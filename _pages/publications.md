---
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can find my all articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

{% include base_path %}

The asterisk **<sup>*</sup>** next to the author's name indicates co-first authorship.


- ### Generative Audio Language Modeling with Continuous-valued Tokens and Masked Next-Token Prediction

  **<u>Shu-wen Yang</u>**, [Byeonggeun Kim](https://sites.google.com/view/byeonggeun-kim), [Kuan-Po Huang](https://scholar.google.com/citations?user=cgTcTMoAAAAJ&hl=zh-TW), [Qingming Tang](https://home.ttic.edu/~qmtang/), [Huy Phan](https://pquochuy.github.io/), [Bo-Ru Lu](https://nlp.borulu.com/), [Harsha Sundar](https://scholar.google.com/citations?user=2-kP7ZQAAAAJ&hl=zh-TW), [Shalini Ghosh](https://sites.google.com/site/shalinighosh), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Chieh-Chi Kao](https://scholar.google.com/citations?user=BFP-otkAAAAJ&hl=en), [Chao Wang](https://scholar.google.com/citations?user=Ucw6EJAAAAAJ&hl=en)\\
  in **ICML**, 2025\\
  [arxiv (comming soon)]()


- ### IMPACT: Iterative Mask-based Parallel Decoding for Text-to-Audio Generation with Diffusion Modeling

  [Kuan-Po Huang](https://scholar.google.com/citations?user=cgTcTMoAAAAJ&hl=zh-TW), **<u>Shu-wen Yang</u>**, [Huy Phan](https://pquochuy.github.io/), [Bo-Ru Lu](https://nlp.borulu.com/), [Byeonggeun Kim](https://sites.google.com/view/byeonggeun-kim), [Sashank Macha](https://scholar.google.com/citations?user=0wOpyncAAAAJ&hl=en), [Qingming Tang](https://home.ttic.edu/~qmtang/), [Shalini Ghosh](https://sites.google.com/site/shalinighosh), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Chieh-Chi Kao](https://scholar.google.com/citations?user=BFP-otkAAAAJ&hl=en), [Chao Wang](https://scholar.google.com/citations?user=Ucw6EJAAAAAJ&hl=en)\\
  in **ICML**, 2025\\
  [arxiv (comming soon)]()


- ### Dynamic-superb phase-2: A collaboratively expanding benchmark for measuring the capabilities of spoken language models with 180 tasks

  [Chien-yu Huang](https://scholar.google.com.tw/citations?user=1Xfc3ikAAAAJ&hl=zh-TW), [Wei-Chih Chen](https://scholar.google.com/citations?user=1spRjbMAAAAJ&hl=en), **<u>Shu-wen Yang</u>**, [Andy T. Liu](https://andi611.github.io/), [Chen-An Li](https://scholar.google.com/citations?user=QOAVnwQAAAAJ&hl=zh-TW), [Yu-Xiang Lin](https://scholar.google.com.tw/citations?user=cZZ5vD8AAAAJ&hl=zh-TW), [Wei-Cheng Tseng](https://scholar.google.com.tw/citations?user=-d6aNP0AAAAJ&hl=zh-TW) et al.\\
  in **ICLR**, 2025\\
  [arxiv](https://arxiv.org/abs/2411.05361) / [code](https://github.com/dynamic-superb/dynamic-superb)


- ### A Large-Scale Evaluation of Speech Foundation Models

  **<u>Shu-wen Yang</u>**, [Heng-Jui Chang](https://people.csail.mit.edu/hengjui/), [Zili Huang](https://scholar.google.com/citations?user=iQ-S0fQAAAAJ&hl=en), [Andy T. Liu](https://andi611.github.io/), [Cheng-I Lai](https://people.csail.mit.edu/clai24/), [Haibin Wu](https://hbwu-ntu.github.io/), [Jiatong Shi](http://shijt.site/), [Xuankai Chang](https://www.xuankaic.com/), Hsiang-Sheng Tsai, [Wen-Chin Huang](https://unilight.github.io/), Tzu-hsun Feng, [Po-Han Chi](https://scholar.google.com/citations?user=SiyicoEAAAAJ&hl=zh-TW), [Yist Y. Lin](https://scholar.google.com/citations?user=0lrZq9MAAAAJ&hl=en), [Yung-Sung Chuang](https://people.csail.mit.edu/yungsung/), Tzu-Hsien Huang, [Wei-Cheng Tseng](https://scholar.google.com.tw/citations?user=-d6aNP0AAAAJ&hl=zh-TW), [Kushal Lakhotia](https://scholar.google.com/citations?user=w9W6zXUAAAAJ&hl=en), [Shang-Wen Li](https://swdanielli.github.io/), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **IEEE/ACM Transactions on Audio Speech and Language Processing**, 2024\\
  [arxiv](https://arxiv.org/abs/2404.09385) (preferred) / [ieee](https://ieeexplore.ieee.org/document/10502279) / [code](https://github.com/s3prl/s3prl)


- ### SUPERB @ SLT 2022: Challenge on Generalization and Efficiency of Self-Supervised Speech Representation Learning

  Tzu-hsun Feng, Annie Dong, [Ching-Feng Yeh](https://scholar.google.com.tw/citations?hl=zh-TW&user=P7ma7pAAAAAJ&view_op=list_works&sortby=pubdate), **<u>Shu-wen Yang</u>**, [Tzu-Quan Lin](https://scholar.google.com.tw/citations?user=efKSVR8AAAAJ&hl=zh-TW), [Jiatong Shi](http://shijt.site/), [Kai-Wei Chang](https://kwchang.org/), [Zili Huang](https://scholar.google.com/citations?user=iQ-S0fQAAAAJ&hl=en), [Haibin Wu](https://hbwu-ntu.github.io/), [Xuankai Chang](https://www.xuankaic.com/), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Shang-Wen Li](https://swdanielli.github.io/), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **SLT**, 2022\\
  [arxiv](https://arxiv.org/abs/2210.08634) / [code](https://github.com/B06901052/DeepSpeed/tree/superb-challenge) / [website](https://www.slt2022.org/challenge-sessions.php)


- ### A Comparative Study of Self-Supervised Speech Representation Based Voice Conversion

  [Wen-Chin Huang](https://unilight.github.io/), **<u>Shu-wen Yang</u>**, [Tomoki Hayashi](https://kan-bayashi.github.io/), [Tomoki Toda](https://sites.google.com/site/tomokitoda/home_eng)\\
  in **IEEE Journal of Selected Topics in Signal Processing**, 2022\\
  [arxiv](https://arxiv.org/abs/2207.04356) / [code](https://github.com/unilight/s3prl-vc)


- ### Self-supervised Representation Learning for Speech Processing

  [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Tara Sainath](https://sites.google.com/site/tsainath/), [Karen Livescu](https://home.ttic.edu/~klivescu/), [Shang-Wen Li](https://swdanielli.github.io/), **<u>Shu-wen Yang</u>**, [Katrin Kirchhoff](https://www.amazon.science/author/katrin-kirchhoff)\\
  in **NAACL**, 2022\\
  [tutorial proposal](https://aclanthology.org/2022.naacl-tutorials.2/) / [video](https://www.youtube.com/watch?v=22IE8swBEbQ&list=PLmBa5a9Ne6fU-1H0EIFjoUJSjSmB1RcSx)


- ### Investigating Self-Supervised Learning for Speech Enhancement and Separation

  [Zili Huang](https://scholar.google.com/citations?user=iQ-S0fQAAAAJ&hl=en), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), **<u>Shu-wen Yang</u>**, [Paola Garcia](https://scholar.google.com/citations?user=fAXgPckAAAAJ&hl=en), [Sanjeev Khudanpur](https://engineering.jhu.edu/faculty/sanjeev-khudanpur/)\\
  in **ICASSP**, 2022\\
  [arxiv](https://arxiv.org/abs/2203.07960) / [code](https://github.com/s3prl/s3prl)


- ### DistilHuBERT: Speech Representation Learning by Layer-wise Distillation of Hidden-unit BERT

  [Heng-Jui Chang](https://people.csail.mit.edu/hengjui/), **<u>Shu-wen Yang</u>**, [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **ICASSP**, 2022\\
  [arxiv](https://arxiv.org/abs/2110.01900) / [code](https://github.com/s3prl/s3prl) / [huggingface](https://huggingface.co/ntu-spml/distilhubert)


- ### S3PRL-VC: Open-Source Voice Conversion Framework with Self-Supervised Speech Representations

  [Wen-Chin Huang](https://unilight.github.io/), **<u>Shu-Wen Yang</u>**, [Tomoki Hayashi](https://kan-bayashi.github.io/), [Hung-Yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Tomoki Toda](https://sites.google.com/site/tomokitoda/home_eng)\\
  in **ICASSP**, 2022\\
  [arxiv](https://arxiv.org/abs/2110.06280) / [code](https://github.com/unilight/s3prl-vc) / [demo](https://huggingface.co/spaces/unilight/s3prl-vc-vcc2020)


- ### SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities

  Hsiang-Sheng Tsai**<sup>*</sup>**, [Heng-Jui Chang](https://people.csail.mit.edu/hengjui/)**<sup>*</sup>**, [Wen-Chin Huang](https://unilight.github.io/)**<sup>*</sup>**, [Zili Huang](https://scholar.google.com/citations?user=iQ-S0fQAAAAJ&hl=en)**<sup>*</sup>**, [Kushal Lakhotia](https://scholar.google.com/citations?user=w9W6zXUAAAAJ&hl=en)**<sup>*</sup>**, **<u>Shu-wen Yang</u>**, Shuyan Dong, [Andy T. Liu](https://andi611.github.io/), [Cheng-I Jeff Lai](https://people.csail.mit.edu/clai24/), [Jiatong Shi](http://shijt.site/), [Xuankai Chang](https://www.xuankaic.com/), Phil Hall, Hsuan-Jui Chen, [Shang-Wen Li](https://swdanielli.github.io/), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **ACL**, 2022\\
  [arxiv](https://arxiv.org/abs/2203.06849) / [video](https://www.youtube.com/watch?v=S8HJVCxxdy0) / [website](https://superbbenchmark.org/) / [code](https://github.com/s3prl/s3prl)


- ### DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering

  [Guan-Ting Lin](https://daniellin94144.github.io/), [Yung-Sung Chuang](https://people.csail.mit.edu/yungsung/), Ho-Lam Chung, **<u>Shu-wen Yang</u>**, Hsuan-Jui Chen, Shuyan Dong, [Shang-Wen Li](https://swdanielli.github.io/), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Lin-shan Lee](https://speech.ee.ntu.edu.tw/previous_version/lslNew.htm)\\
  in **Interspeech**, 2022\\
  [arxiv](https://arxiv.org/abs/2203.04911)


- ### An Exploration of Self-Supervised Pretrained Representations for End-to-End Speech Recognition

  [Xuankai Chang](https://www.xuankaic.com/), Takashi Maekaku, Pengcheng Guo, Jing Shi, Yen-Ju Lu, Aswin Shanmugam Subramanian, Tianzi Wang, **<u>Shu-wen Yang</u>**, [Yu Tsao](https://www.citi.sinica.edu.tw/pages/yu.tsao/index_en.html), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe)\\
  in **ASRU**, 2021\\
  [arxiv](https://arxiv.org/abs/2110.04590) / [code](https://github.com/espnet/espnet)


- ### SUPERB: Speech processing Universal PERformance Benchmark

  **<u>Shu-wen Yang</u>**, [Po-Han Chi](https://scholar.google.com/citations?user=SiyicoEAAAAJ&hl=zh-TW), [Yung-Sung Chuang](https://people.csail.mit.edu/yungsung/), [Cheng-I Jeff Lai](https://people.csail.mit.edu/clai24/), [Kushal Lakhotia](https://scholar.google.com/citations?user=w9W6zXUAAAAJ&hl=en), [Yist Y. Lin](https://scholar.google.com/citations?user=0lrZq9MAAAAJ&hl=en), [Andy T. Liu](https://andi611.github.io/), [Jiatong Shi](http://shijt.site/), [Xuankai Chang](https://www.xuankaic.com/), [Guan-Ting Lin](https://daniellin94144.github.io/), Tzu-Hsien Huang, [Wei-Cheng Tseng](https://scholar.google.com.tw/citations?user=-d6aNP0AAAAJ&hl=zh-TW), Ko-tik Lee, [Da-Rong Liu](https://scholar.google.com.tw/citations?user=qJ5zXNIAAAAJ&hl=zh-TW), [Zili Huang](https://scholar.google.com/citations?user=iQ-S0fQAAAAJ&hl=en), Shuyan Dong, [Shang-Wen Li](https://swdanielli.github.io/), [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe), [Abdelrahman Mohamed](https://www.cs.toronto.edu/~asamir/), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **Interspeech**, 2021\\
  [arxiv](https://arxiv.org/abs/2105.01051) / [video](https://www.youtube.com/watch?v=zd9fiVvej0k) / [website](https://superbbenchmark.org/) / [code](https://github.com/s3prl/s3prl)


- ### S3PRL: The Self-Supervised Speech Pre-training and Representation Learning Toolkit

  [Andy T Liu](https://andi611.github.io/)**<sup>*</sup>**, **<u>Shu-wen Yang</u><sup>*</sup>**\\
  on **GitHub repository**, 2020\\
  [code](https://github.com/s3prl/s3prl) / [website](https://s3prl.github.io/s3prl/) / [video](https://www.youtube.com/watch?v=PkMFnS6cjAc)


- ### Understanding Self-Attention of Self-Supervised Audio Transformers

  **<u>Shu-wen Yang</u>**, [Andy T Liu](https://andi611.github.io/), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **Interspeech**, 2020\\
  in **ICML Workshop on Self-supervision in Audio and Speech**, 2020\\
  [arxiv](https://arxiv.org/abs/2006.03265) / [video](https://slideslive.com/38930730/understanding-selfattention-of-selfsupervised-audio-transformers)


- ### Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders

  [Andy T Liu](https://andi611.github.io/), **<u>Shu-wen Yang</u>**, [Po-Han Chi](https://scholar.google.com/citations?user=SiyicoEAAAAJ&hl=zh-TW), [Po-chun Hsu](https://scholar.google.com/citations?user=JZrV0tcAAAAJ&hl=en), [Hung-yi Lee](https://speech.ee.ntu.edu.tw/~hylee/index.php)\\
  in **ICASSP**, 2020\\
  [arxiv](https://arxiv.org/abs/1910.12638) / [code](https://github.com/s3prl/s3prl) / [video](https://www.youtube.com/watch?v=THylmb3hZVs)
